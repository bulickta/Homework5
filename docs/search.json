[
  {
    "objectID": "Homework5.html",
    "href": "Homework5.html",
    "title": "ST 558 Homework5",
    "section": "",
    "text": "What is the purpose of using cross-validation when fitting a random forest model?\n\n\nCross-validation can first help with model selection for a smaller data set where separating into training and test sets might not leave enough training data for effective modelling. Alternatively, Cross-validation can help to select the best value for the tuning parameter (value of m) of the random forest.\n\n\nDescribe the bagged tree algorithm.\n\n\nThe bagged tree algorithm essentially involves repeatedly sampling (with replacement) from the original sample, training a tree on the new sample and calculating predictions, and then averaging each prediction across the number of iterations of the algorithm, so ultimately there is a mean value for each prediction. Alternatively, in a classification version the same process is completed, but the “mean” value is instead just selected to be the most common result for each prediction.\n\n\nWhat is meant by a general linear model?\n\n\nA general linear model is a model that can take in both continuous and categorical data as predictors, and expects a continuous reponse variable with normally distributed residuals. This is in contrast to a “generalized” linear model with more flexible options for the reponse and flexibility in the expected distribution of the residuals.\n\n\nWhen fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to do differently as compared to when it is not included in the model?\n\n\nAn interaction term allows the model to account for the possibility that the relationship between a certain predictor and the response may be influenced by a relationship between the predictor and another predictor. For instance, if there is a relationship between the weight of a vehicle and its expected miles per gallon, this relationship might also be changed by the number of cyclinders in the vehicle’s engine, separate from the direct relationship between cylinders and MPG. An interaction term allows the model to account for this additional complexity.\n\n\nWhy do we split our data into a training and test set?\n\n\nSplitting data into a training set and a test set is what allows for the comparison of prediction efficacy across different models, as several models can be trained on the same training set, and then a metric for model error, such as RMSE, can be compared to see which is “better” at prediction."
  },
  {
    "objectID": "Homework5.html#task-1-conceptual-questions",
    "href": "Homework5.html#task-1-conceptual-questions",
    "title": "ST 558 Homework5",
    "section": "",
    "text": "What is the purpose of using cross-validation when fitting a random forest model?\n\n\nCross-validation can first help with model selection for a smaller data set where separating into training and test sets might not leave enough training data for effective modelling. Alternatively, Cross-validation can help to select the best value for the tuning parameter (value of m) of the random forest.\n\n\nDescribe the bagged tree algorithm.\n\n\nThe bagged tree algorithm essentially involves repeatedly sampling (with replacement) from the original sample, training a tree on the new sample and calculating predictions, and then averaging each prediction across the number of iterations of the algorithm, so ultimately there is a mean value for each prediction. Alternatively, in a classification version the same process is completed, but the “mean” value is instead just selected to be the most common result for each prediction.\n\n\nWhat is meant by a general linear model?\n\n\nA general linear model is a model that can take in both continuous and categorical data as predictors, and expects a continuous reponse variable with normally distributed residuals. This is in contrast to a “generalized” linear model with more flexible options for the reponse and flexibility in the expected distribution of the residuals.\n\n\nWhen fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to do differently as compared to when it is not included in the model?\n\n\nAn interaction term allows the model to account for the possibility that the relationship between a certain predictor and the response may be influenced by a relationship between the predictor and another predictor. For instance, if there is a relationship between the weight of a vehicle and its expected miles per gallon, this relationship might also be changed by the number of cyclinders in the vehicle’s engine, separate from the direct relationship between cylinders and MPG. An interaction term allows the model to account for this additional complexity.\n\n\nWhy do we split our data into a training and test set?\n\n\nSplitting data into a training set and a test set is what allows for the comparison of prediction efficacy across different models, as several models can be trained on the same training set, and then a metric for model error, such as RMSE, can be compared to see which is “better” at prediction."
  },
  {
    "objectID": "Homework5.html#task-2-fitting-models",
    "href": "Homework5.html#task-2-fitting-models",
    "title": "ST 558 Homework5",
    "section": "Task 2: Fitting Models",
    "text": "Task 2: Fitting Models\n\nrawdata &lt;- read_csv(\"./heart.csv\")\n\nRows: 918 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Sex, ChestPainType, RestingECG, ExerciseAngina, ST_Slope\ndbl (7): Age, RestingBP, Cholesterol, FastingBS, MaxHR, Oldpeak, HeartDisease\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmissing &lt;- colSums(is.na(rawdata))\nmissing\n\n           Age            Sex  ChestPainType      RestingBP    Cholesterol \n             0              0              0              0              0 \n     FastingBS     RestingECG          MaxHR ExerciseAngina        Oldpeak \n             0              0              0              0              0 \n      ST_Slope   HeartDisease \n             0              0 \n\ngg&lt;-ggplot(rawdata,aes(x=as_factor(HeartDisease)))\na &lt;- gg+geom_bar()+labs(x=\"Heart Disease\")\nb &lt;- gg+geom_count(aes(y=Sex))+labs(x=\"Heart Disease\")\nc &lt;- gg+geom_count(aes(y=ChestPainType))+labs(x=\"Heart Disease\")\nd &lt;- gg+geom_count(aes(y=FastingBS))+labs(x=\"Heart Disease\")\ne &lt;- gg+geom_count(aes(y=RestingECG))+labs(x=\"Heart Disease\")\nf &lt;- gg+geom_count(aes(y=ExerciseAngina))+labs(x=\"Heart Disease\")\ng &lt;- gg+geom_boxplot(aes(y=Age,fill=as_factor(HeartDisease)))+labs(x=\"Heart Disease\")\nh &lt;- gg+geom_boxplot(aes(y=RestingBP,fill=as_factor(HeartDisease)))+labs(x=\"Heart Disease\")\ni &lt;- gg+geom_boxplot(aes(y=Cholesterol,fill=as_factor(HeartDisease)))+labs(x=\"Heart Disease\")\nj &lt;- gg+geom_boxplot(aes(y=MaxHR,fill=as_factor(HeartDisease)))+labs(x=\"Heart Disease\")\nk &lt;- gg+geom_boxplot(aes(y=Oldpeak,fill=as_factor(HeartDisease)))+labs(x=\"Heart Disease\")\n\nggarrange(a,b,c,d,e,f,g,h,i,j,k,ncol=6,nrow=2)\n\n\n\n\n\n\n\ncleandata &lt;- rawdata |&gt;\n  mutate(HeartDisease = factor(HeartDisease)) |&gt;\n  select(Age:Oldpeak,HeartDisease)\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  }
]